{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\" and remove every line containing the expression: \"raise ...\" (if you leave such a line your code will not run).\n",
    "\n",
    "Do not remove any cell from the notebook you downloaded. You can add any number of cells (and remove them if not more necessary). \n",
    "\n",
    "## IMPORTANT: make sure to rerun all the code from the beginning to obtain the results for the final version of your notebook, since this is the way we will do it before evaluating your notebook!!!\n",
    "\n",
    "Fill in your name and id number (numero matricola) below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Victor Miguel Velazquez Espitia\"\n",
    "ID_number = int(\"2043179\")\n",
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ef6a856bf6996469a4cfb2175d6df79",
     "grade": false,
     "grade_id": "cell-0b45e876b590deca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Classification on Wine Dataset\n",
    "\n",
    "### Dataset description\n",
    "\n",
    "We will be working with a dataset on wines from the UCI machine learning repository\n",
    "(http://archive.ics.uci.edu/ml/datasets/Wine ). It contains data for 178 instances. \n",
    "The dataset is the results of a chemical analysis of wines grown in the same region\n",
    "in Italy but derived from three different cultivars. The analysis determined the\n",
    "quantities of 13 constituents found in each of the three types of wines. \n",
    "\n",
    "### The features in the dataset are:\n",
    "\n",
    "- Alcohol\n",
    "- Malic acid\n",
    "- Ash\n",
    "- Alcalinity of ash\n",
    "- Magnesium\n",
    "- Total phenols\n",
    "- Flavanoids\n",
    "- Nonflavanoid phenols\n",
    "- Proanthocyanins\n",
    "- Color intensity\n",
    "- Hue\n",
    "- OD280/OD315 of diluted wines\n",
    "-Proline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de27abe278eac61bd289180959f88630",
     "grade": false,
     "grade_id": "cell-12773fe6d001aa0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We first import all the packages that are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c82bec8fe7400a21b5b3de069c954ab",
     "grade": false,
     "grade_id": "cell-18fb2059facb1757",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66c1ac60874c5ce72ce214211c19bb3f",
     "grade": false,
     "grade_id": "cell-ecb42095dd5d61b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(ID_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef16821f9da27091d8ede41df14b6cbc",
     "grade": false,
     "grade_id": "cell-7e0a653355f6eaf6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Perceptron\n",
    "We will implement the perceptron and use it to learn a halfspace with 0-1 loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3b82d7bc9cf6d8a1a756094ba3e077e9",
     "grade": false,
     "grade_id": "cell-afd6e34f8a3801f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Load the dataset from scikit learn and then split in training set and test set (50%-50%) after applying a random permutation to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from scikit learn\n",
    "wine = datasets.load_wine()\n",
    "# Get input and output data from the dataset\n",
    "X = wine.data\n",
    "Y = wine.target\n",
    "# Create new labels\n",
    "Y = np.where(Y == 0, -1, Y)\n",
    "Y = np.where(Y == 2, -1, Y)\n",
    "# Let's get the number of features\n",
    "d = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c611e9863df5d7b5255996608a3a2133",
     "grade": false,
     "grade_id": "cell-ec8c87debd43b523",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### Helper functions, do not modify them. You will need them for the first TODO\n",
    "def check_constraints(labels, all_possibile_labels, min_num_istances):\n",
    "    # Count the number of occurrences using numpy\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    if len(all_possibile_labels) != len(unique):\n",
    "        return True\n",
    "    if (counts >= min_num_istances).all():\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def need_new_shuffle(y_train, y_test, all_possibile_labels, min_num_istances): \n",
    "    return (check_constraints(y_train, all_possibile_labels, min_num_istances) or \n",
    "            check_constraints(y_test, all_possibile_labels, min_num_istances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "957aa6aa31dc6374050deb2a164240dd",
     "grade": false,
     "grade_id": "cell-d02ac71a8713e5a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 1\n",
    "# Write a function (create_train_val_test_datasets) which takes as input a dataset and returns 2 datasets: \n",
    "# S_t and S_test (different runs are supposed) to return different datasets.\n",
    "# Write a function (create_train_val_test_datasets_with_constraints) which splits our data in S_t and S_test with \n",
    "# the additional constraint that in each dataset we MUST have more than min_num_istances per class.\n",
    "# Each dataset is represented as a matrix m \\times d (numpy ndarray), where m is the number of data and d is the \n",
    "# number of features.\n",
    "# To solve this TODO use the functions we provide you: check_constraints and need_new_shuffle\n",
    "\n",
    "def create_train_val_test_datasets(features : np.ndarray, labels: np.ndarray, m_t : int, m_test : int):\n",
    "    '''\n",
    "    Create training (S_t) and test (S_test) sets starting from a dataset. \n",
    "    This function shuffles the complete dataset before creating the subsets. \n",
    "    If you call this function twice it is expected to get different S_t, S_test. \n",
    "    \n",
    "    :param features: NumPy ndarray containing all the input data data we can use\n",
    "    :param labels: NumPy ndarray containing all the labels we have\n",
    "    :param m_t: Number of samples for the training dataset\n",
    "    :param m_test: Number of samples for the test dataset\n",
    "    \n",
    "    :returns: (x_train, y_train, x_test, y_test)\n",
    "    :rtype: tuple\n",
    "        WHERE\n",
    "        x_train : np.ndarray features in the training dataset\n",
    "        y_train : np.ndarray labels in the training dataset\n",
    "        x_test : np.ndarray features in the test dataset\n",
    "        y_test : np.ndarray labels in the test dataset\n",
    "    '''\n",
    "    # SUGGESTION: Use the function np.random.permutation (see the documentation) to create a permutation of the \n",
    "    #             dataset indexes. Then use these shuffled indexes to create S_t, S_val, S_test\n",
    "    # YOUR CODE HERE\n",
    "    data = np.c_[features, labels]                          #put features and labels in same numpy array\n",
    "    data = np.random.permutation(data)                      #Make the permutation of the data\n",
    "    labels = data.T[features.shape[1]]                      #get the new labels\n",
    "    features = np.delete(data, features.shape[1], axis = 1) #delete the labels so we keep the features\n",
    "    S_t_features=features[0:m_t]                            #Divide between the training and test for both features and labels\n",
    "    S_test_features=features[m_t:m_t+m_test]\n",
    "    S_t_labels=labels[0:m_t]\n",
    "    S_test_labels=labels[m_t:m_t+m_test]\n",
    "\n",
    "    x_train = S_t_features[:,:]                             #Set it as X and Y data i.e features and labels with proper dimension\n",
    "    x_test  = S_test_features[:,:]\n",
    "    y_train = S_t_labels[:].reshape(-1,1)\n",
    "    y_test  = S_test_labels[:].reshape(-1,1)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def create_train_val_test_datasets_with_constraints(features : np.ndarray, labels: np.ndarray, m_t : int, \n",
    "                                                    m_test : int, min_num_istances : int):\n",
    "    '''\n",
    "    Same as function above but now we are imposing the constraints: the splitted datasets are assumed to contain \n",
    "    at least min_num_istances per class.\n",
    "    \n",
    "    ...\n",
    "    :param min_num_istances: Minimum number of istances per class in each of the splitted datasets\n",
    "    ...\n",
    "    \n",
    "    '''\n",
    "    all_possibile_labels = np.unique(labels)                                #get the labels \n",
    "    #YOUR CODE HERE\n",
    "\n",
    "    data = np.c_[features, labels]\n",
    "    data = np.random.permutation(data)\n",
    "    labels = data.T[features.shape[1]]\n",
    "    features = np.delete(data, features.shape[1], axis = 1)\n",
    "    x_train=features[0:m_t]\n",
    "    x_test=features[m_t:m_t+m_test]\n",
    "    y_train=labels[0:m_t].reshape(-1,1)\n",
    "    y_test=labels[m_t:m_t+m_test].reshape(-1,1)\n",
    "\n",
    "    #Do the contraint\n",
    "    #Keep shuffling until min number of instance satisfied for each parameter\n",
    "    while need_new_shuffle(y_train, y_test, all_possibile_labels,min_num_istances) == True:  \n",
    "        data = np.c_[features, labels]\n",
    "        data = np.random.permutation(data)\n",
    "        labels = data.T[features.shape[1]]\n",
    "        features = np.delete(data, features.shape[1], axis = 1)\n",
    "        x_train=features[0:m_t]\n",
    "        x_test=features[m_t:m_t+m_test]\n",
    "        y_train=labels[0:m_t].reshape(-1,1)\n",
    "        y_test=labels[m_t:m_t+m_test].reshape(-1,1)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "m_t = 80\n",
    "x_train, y_train, x_test, y_test = create_train_val_test_datasets_with_constraints(X, Y, m_t, len(Y)-m_t, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "838724b9559e75799f3fe903aafc9b85",
     "grade": true,
     "grade_id": "cell-e51332c46f70a2fd",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert x_train.shape == (m_t,       x_train.shape[1]) # here we are comparing two tuples (it is an element wise comparison)\n",
    "assert x_test.shape  == (len(Y)-m_t, x_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d64cc58d083d2f6bc0c623724411155",
     "grade": false,
     "grade_id": "cell-ac04c6e54551b392",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's add a 1 in front of each sample so that we can use a vector to describe all the coefficients of the model.\n",
    "# Do not run this cell multiple times otherwise you will continue adding ones... \n",
    "# (we add the assert to avoid such issue)\n",
    "\n",
    "assert x_train.shape[1] == d\n",
    "assert x_test.shape[1] == d \n",
    "\n",
    "x_train = np.hstack((np.ones((x_train.shape[0],1)), x_train))\n",
    "x_test  = np.hstack((np.ones((x_test.shape[0],1)),  x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03f294d2454985bd2759e7046cd66764",
     "grade": false,
     "grade_id": "cell-e62f679cad1d169b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 2** Now complete the function *perceptron*. Since the perceptron does not terminate if the data is not linearly separable, your implementation should return the desired output (see below) if it reached the termination condition seen in class or if a maximum number of iterations have already been run, where 1 iteration corresponds to 1 update of the perceptron weights. If the perceptron returns because the maximum number of iterations has been reached, you should return an appropriate model (the best seen along the iterations). \n",
    "\n",
    "The input parameters to pass are:\n",
    "- $X$: the matrix of input features, one row for each sample\n",
    "- $Y$: the vector of labels for the input features matrix X\n",
    "- $max\\_num\\_iterations$: the maximum number of iterations for running the perceptron\n",
    "\n",
    "The output values are:\n",
    "- $best\\_w$: the vector with the coefficients of the best model\n",
    "- $best\\_error$: the *fraction* of missclassified samples for the best model\n",
    "- $w\\_iters$: a list of the coefficients found by the algorithm, in those iterations in which the error decreases. This is an 'auxiliary output' (it is not needed for the actual algorithm) that will allows us to have a better insight on the algorithm's behaviour\n",
    "- $error\\_iters$: a list of the *fractions* of missclassified samples for every model found through the same iterations as for the list above. Again an auxiliary output.\n",
    "\n",
    "\n",
    "**Auxiliary functions**\n",
    "\n",
    "In order to correclty complete the perceptron function it is warmly recommended to define some auxiliary functions (\"*find_missclassified*\" and \"*choose_missclassified*\"). \n",
    "\n",
    "\n",
    "\"__find_missclassified__\"\n",
    "This function looks for missclassified data points in the dataset $X$.\n",
    "\n",
    "The input parameters to pass are:\n",
    "- $X$: the matrix of input features, one row for each sample\n",
    "- $Y$: the vector of labels for the input features matrix X\n",
    "- $curr\\_w$: the current value of the parameter vector *w*\n",
    "\n",
    "The output value is:\n",
    "- $missclassified\\_indeces$: a numpy array cointaining all the missclassified indeces  \n",
    "\n",
    "\n",
    "\"__choose_missclassified__\"\n",
    "This function return one single index choosen from a array of indeces. If the array is empty it returns a non valid index: -1. \n",
    "\n",
    "The input parameters to pass are:\n",
    "- $missclassified\\_indeces$: numpy arrya containing missclassified indeces\n",
    "\n",
    "The output value is:\n",
    "- $index$: Integer (or np.int64) containing the choosen index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4cdc61da992cca686d30b4de4d6a8564",
     "grade": false,
     "grade_id": "cell-3a616874d5d69312",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "\n",
    "def find_missclassified(X,Y,curr_w):\n",
    "    # Here you can use np.argwhere to find which model predictions are correct (this is faster than a for loop)\n",
    "    # but be carefull on the dimensions of your predictions vector and Y vector.\n",
    "    # YOUR CODE HERE\n",
    "    a = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        a[i]=Y[i]*np.matmul(curr_w, X[i,:].reshape(-1,1))\n",
    "    missclassified_indeces = np.argwhere(a<=0)\n",
    "    return missclassified_indeces.reshape(-1,)\n",
    "\n",
    "def choose_missclassified(missclassified_indeces):\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError() # Remove this line\n",
    "    if len(missclassified_indeces) == 0:\n",
    "        index = -1\n",
    "    else:\n",
    "        index = np.random.choice(missclassified_indeces)   \n",
    "    return index\n",
    "\n",
    "def perceptron(X,Y,max_num_iterations):\n",
    "    #INITIALIZATION\n",
    "    curr_w = np.zeros(X.shape[1])   #row vector\n",
    "    best_w = curr_w\n",
    "    num_samples = X.shape[0]\n",
    "    best_error = num_samples+1  # max + 1 number of possible errors \n",
    "    w_iters = []                #matrix 178x13\n",
    "    error_iters = [] \n",
    "    \n",
    "    missclassified_indeces = find_missclassified(X,Y,curr_w)  # You need to assign this variable the proper value\n",
    "    num_missclassified = len(missclassified_indeces)       # You need to assign this variable the proper value\n",
    "    index_missclassified = choose_missclassified(missclassified_indeces)     # You need to assign this variable the proper value\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    num_iter = 1  \n",
    "    while index_missclassified != -1 and num_iter < max_num_iterations: # Remove this False and pass and place the right termination conditionS\n",
    "        # Update rule\n",
    "        #YOUR CODE HERE \n",
    "        curr_w = curr_w+(Y[index_missclassified]*X[index_missclassified,:])\n",
    "\n",
    "        # Update missclassified data points and choose a new missclassified data point\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        missclassified_indeces = find_missclassified(X,Y,curr_w)  # You need to assign this variable the proper value\n",
    "        num_missclassified = len(missclassified_indeces)       # You need to assign this variable the proper value\n",
    "        index_missclassified = choose_missclassified(missclassified_indeces)\n",
    "        #raise NotImplementedError() # Remove this line\n",
    "        # Update (if necessary) the best error achieved together with the best parameter up to now. \n",
    "        # Use copy.copy(curr_w) to copy your current w on \"best_w\" (since these are arrays you would be copying \n",
    "        # only the pointer if you do not use copy.copy) and to append your current w to the list of all w found so far\n",
    "        # Append the current error to the list of all errors found so far\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        if  num_missclassified < best_error:\n",
    "            w_iters.append(curr_w)\n",
    "            error_iters.append(num_missclassified)\n",
    "            best_w = copy.copy(curr_w)\n",
    "            best_error = num_missclassified\n",
    "        num_iter = num_iter+1   \n",
    "\n",
    "    best_error = float(best_error)/float(num_samples)\n",
    "    return best_w, best_error, w_iters, error_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "438f41a962eac3d45493c6001cdc0968",
     "grade": true,
     "grade_id": "cell-f8a90f0c3f9aecb7",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "index = choose_missclassified(np.array(list(range(100))))\n",
    "assert type(index) == np.int64 or type(index) == int or type(index) == np.int32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e68d44e981c0500c5373c42b0764a6c",
     "grade": false,
     "grade_id": "cell-095ff4deafd22d73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error with 100 iterations: 0.2875\n"
     ]
    }
   ],
   "source": [
    "# Now run the perceptron for 100 iterations\n",
    "# We want just to see the output of the algorithm, so we can avoid assigning the auxiliary outputs to actual variables\n",
    "w_found, training_error, _, _ = perceptron(x_train, y_train, 100)\n",
    "print(\"Training error with 100 iterations: \" + str(training_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2962fcea22d2344b6303c8a6d295084",
     "grade": false,
     "grade_id": "cell-a9cd59af4f855da0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 3 \n",
    "# Write a function to compute the fraction of missclassified samples given two nd.array vectors of shape number of \n",
    "# data times 1 (column vectors)\n",
    "def classification_loss(y_target : np.ndarray, predictions : np.ndarray) -> float:\n",
    "    '''\n",
    "    This function computes the fraction of missclassified samples given two vectors: true labels and predictions. \n",
    "    :param y_target: output labels\n",
    "    :param predictions: predictions\n",
    "    \n",
    "    :return: Fraction of missclassified samples\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    error = np.zeros(len(y_target))\n",
    "    for i in range(len(y_target)):\n",
    "        if y_target[i]!=predictions[i]:\n",
    "            error[i] = 1                            #put 1 where there is a mismatch\n",
    "    missclassified_indeces = np.argwhere(error==1)\n",
    "    \n",
    "    #raise NotImplementedError() # Remove this line\n",
    "    return missclassified_indeces.shape[0] / y_target.shape[0]\n",
    "\n",
    "# Write a function to comptue the fraction of missclassified samples for a generic dataset given inputs, targets and \n",
    "# a vector w.\n",
    "def compute_fraction_missclassified(X : np.ndarray, Y : np.ndarray, w : np.ndarray) -> float:\n",
    "    '''\n",
    "    This function computes the fraction of missclassified samples of model parametrized by w on the data X w.r.t. \n",
    "    targets Y. \n",
    "    :param X: input locations\n",
    "    :param Y: targets\n",
    "    :param w: parameters of the model to be tested\n",
    "    \n",
    "    :return: Fraction of missclassified samples\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    a = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        a[i]=Y[i]*np.matmul(w, X[i].reshape(-1,1))\n",
    "    missclassified_indeces = np.argwhere(a<=0)\n",
    "    fraction_missclass = len(missclassified_indeces)/len(Y)\n",
    "    \n",
    "    #raise NotImplementedError() # Remove this line\n",
    "    return fraction_missclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35607e8fa3a23c1c961161be3f18fa51",
     "grade": true,
     "grade_id": "cell-37188909eff59ebb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert classification_loss(np.array([[1],[3]]), np.array([[1],[3]])) == 0\n",
    "assert classification_loss(np.array([[1],[2]]), np.array([[1],[3]])) == 0.5\n",
    "y_labels, y_predictions = np.random.choice(10, 1000000), np.random.choice(10, 1000000)\n",
    "assert np.isclose(classification_loss(y_labels, y_predictions), 0.9, atol=0.01)\n",
    "assert training_error == compute_fraction_missclassified(x_train, y_train, w_found)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f97555da1f74491c0c6d64443c720ea3",
     "grade": false,
     "grade_id": "cell-f450a5d89edf3906",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We now use the best model $w\\_found$ to predict the labels for the test dataset and print the fraction of missclassified samples in the test set (that is an estimate of the true loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4d243c6f58881e06c80a96a04857062",
     "grade": false,
     "grade_id": "cell-cc7f13766f7358b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error for 100 iterations is 0.2875\n",
      "Test Error for 100 iterations is 0.2347\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Error for 100 iterations is {compute_fraction_missclassified(x_train, y_train, w_found):.4f}\")\n",
    "print(f\"Test Error for 100 iterations is {compute_fraction_missclassified(x_test, y_test, w_found):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a3ae01f989aaeadfe8dd2119672a1cb",
     "grade": false,
     "grade_id": "cell-69bcb07038fe4647",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error for 10000 iterations is 0.2000\n",
      "Test Error for 10000 iterations is 0.2143\n"
     ]
    }
   ],
   "source": [
    "# now run the perceptron for 10000 iterations\n",
    "# This time we assign also the auxiliary outputs! They will be useful later on!\n",
    "w_found, training_error, w_list, error_list_train = perceptron(x_train, y_train, 10000)\n",
    "print(f\"Training Error for 10000 iterations is {compute_fraction_missclassified(x_train, y_train, w_found):.4f}\")\n",
    "print(f\"Test Error for 10000 iterations is {compute_fraction_missclassified(x_test, y_test, w_found):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "469c760d825c24576002ab57a889b4f5",
     "grade": false,
     "grade_id": "cell-b46ec6017397bf6c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 4**: Answer in the next cell (you do not need more than 5-7 lines):\n",
    "\n",
    "1- Consider 100 iterations: what relation do you observe between the training error and the (estimated) true loss? Is this what you expected? Explain what you observe and why it does or does not conform to your expectations.\n",
    "\n",
    "2- Consider 10000 iterations, what has changed? Explain what you observe and why it does or does not conform to your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7187b5f0ef3eb2404161444d5c066f9",
     "grade": true,
     "grade_id": "cell-5r8a6b5a5434d45a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)Considering the 100 iteration, it is possible to observe that the training error is greater then the estimated loss. It \n",
    "#does not coincide with my expectations, in fact, usully, the training error is smaller that the estimated loss because\n",
    "#it is evaluated on the same set using for determing the model. However, there could be some cases in which the model\n",
    "#fits better with the data of the training set; it depends by the choice of data set. \n",
    "#, if both training and test error come from the same distributions, then,\n",
    "#  is clear to say that achieving 0.2 in training doesnt mean i reached the best possible w,\n",
    "#  otherwise, training and test errors would be the same.\n",
    "#(2)In the second case (number of iterations equal to 100000) it is possibile to observe that the training error is \n",
    "#smaller than the test error, as I expect because the training error is evaluted over the same data\n",
    "#set using for evalute the model. Moreover, both the training error and the test error descrease. It is what I expect: \n",
    "#More iterations are unnecesary and, because is relatively close to the true error, we can assume its satisfactoy,\n",
    "#  although this might differ with requirements, other algorithms would achieve better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22a76a818ec916fe2a996f8a92d173d9",
     "grade": false,
     "grade_id": "cell-4d2439df9a3690f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 5**: We want to have a better understanding of the hidden behaviour of perceptron algorithm. We indeed defined two auxiliary outputs that should allow us to inspect the training process in more depth. In particular, we want to check if the sequence of models' errors found through the different iterations is characterized by a decreasing trend, with respect to both training and test datasets.\n",
    "\n",
    "The function `perceptron` already returns the sequence of errors, which is ready to be plotted. However, the errors for the test set aren not immediately available: we nonetheless have all different models, thus we can easily compute them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8462f77429396d74fddfc85a0e0866c",
     "grade": false,
     "grade_id": "cell-1b31c939aaccbfcf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 5\n",
    "# Write a function 'error_models' which takes as input a list of models (each of which is a numpy ndarray) and returns\n",
    "# a list of corresponding errors for a generic dataset\n",
    "# Suggestion: you can use 'compute_fraction_missclassified' from above to solve this TODO\n",
    "\n",
    "def error_models(X : np.ndarray, Y : np.ndarray, w_l : list) -> list:\n",
    "    '''\n",
    "    This function computes the fraction of missclassified samples of model parametrized by w on the data X w.r.t. \n",
    "    targets Y. \n",
    "    :param X: input locations\n",
    "    :param Y: targets\n",
    "    :param w: list of arrays (models) to be tested\n",
    "    \n",
    "    :return: List of fraction of missclassified samples for each model\n",
    "    '''\n",
    "    errors = []\n",
    "    # YOUR CODE HERE\n",
    "    for i in range(len(w_l)):\n",
    "        errors.append(compute_fraction_missclassified(X,Y,w_l[i]))\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6413b5edf9131d64c721aa3856f6edf0",
     "grade": true,
     "grade_id": "cell-35cfce3521a586e5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(error_models(x_test, y_test, w_list)) == len(error_list_train)\n",
    "assert len(error_models(x_test, y_test, w_list)) <= 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d393b4a366154f7ac52e5c3cf575b4be",
     "grade": false,
     "grade_id": "cell-d46c1c56214026b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's make 'error_list_train' a fraction of the missclassified samples by dividing for the size of the training set\n",
    "error_list_train = np.array(error_list_train)/x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "301fc11fbbee6176a5a66ae731ee1afe",
     "grade": false,
     "grade_id": "cell-91232f80b209e445",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Perceptron test error behaviour')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_list_test = error_models(x_test, y_test, w_list)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].plot([i for i in range(len(w_list))], error_list_train, linewidth=2)\n",
    "axes[0].set_xlabel('Error-decreasing iteration')\n",
    "axes[0].set_ylabel('Training error')\n",
    "axes[0].set_title('Perceptron training error behaviour')\n",
    "axes[1].plot([i for i in range(len(w_list))], error_list_test, linewidth=2)\n",
    "axes[1].set_xlabel('Error-decreasing iteration')\n",
    "axes[1].set_ylabel('Test error')\n",
    "axes[1].set_title('Perceptron test error behaviour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6762b84b460b249198bd0a496c16912a",
     "grade": false,
     "grade_id": "cell-3f70a09649060ece",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 6**: Answer in the next cell (you do not need more than 5-7 lines):\n",
    "\n",
    "Consider the plot above. How do the two errors compare? Can you identify a particular property of one of them? Why doesn't the other have it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0c3b1b8817b584472c6fa67e5721dc31",
     "grade": true,
     "grade_id": "cell-5g8a6b5a5434d45a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The graph on the left, \"Perceptron trainig error behaviour\", describes the behaviour of the error as w\n",
    "#changes, considering the w determined with the perceptron algorithm (defined in todo 2) for every iteration when \n",
    "#the numbers of error decreses. Therefore, as the model has been determined with respect to the training set, if \n",
    "#I apply it to the training set I expect that the w determined fits well with the reality and so the error decreses as\n",
    "#it is shown in the first graph. On the other hand, if I apply the model determined with the trainig set to the test set\n",
    "#I will expect to do more errors because the list of w are not determined with the test set. This is conformed with the\n",
    "#graph on the left \"Perceptron test error behaviour\" that does not decrease for every w in w_list.\n",
    "# In both we can percieve a similar correspondance, both tend to the decrease of the error.\n",
    "#  It is remarkable that in the training set, the error its maintained in decreasing performance.\n",
    "#  While the test error, founds first a local minimum, to then increase, and finally continue corresponding the expected behaviour. \n",
    "# This is because of the particular property,\n",
    "#  that we cannot expect the same constant decreasing behaviour as in the training set, because of the simple reason, this is new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ee804dacb6dc36e52aa75ef49bd0823",
     "grade": false,
     "grade_id": "cell-ceceb8d79bdbb44c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Logistic Regression\n",
    "Now we use logistic regression, as implemented in Scikit-learn, to predict labels. We first do it for 2 labels and then for 3 labels. We will also plot the decision region of logistic regression.\n",
    "\n",
    "We first load the dataset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f987eb7258f14865ba47ac14effdc10",
     "grade": false,
     "grade_id": "cell-f0438d3eda59cd16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Let's reinitialize the random seed \n",
    "random.seed(ID_number)\n",
    "np.random.seed(ID_number)\n",
    "\n",
    "# In the following we will keep the dataset with only two classes (which we aggregated before)\n",
    "m_t = 80\n",
    "x_train, y_train, x_test, y_test = create_train_val_test_datasets_with_constraints(X, Y, m_t, len(Y)-m_t, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99512e4cd5717eddcf9dc7a2f5519ad0",
     "grade": false,
     "grade_id": "cell-2ac0dfd0d9156863",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To define a logistic regression model in Scikit-learn use the instruction\n",
    "\n",
    "$linear\\_model.LogisticRegression(C=1e5, max\\_iter=?)$\n",
    "\n",
    "$C$ is a parameter related to *regularization*, a technique that\n",
    "we will see later in the course. Setting it to a high value is almost\n",
    "as ignoring regularization, so the instruction above corresponds to the\n",
    "logistic regression you have seen in class. Choose the proper number of iterations: max_iter.\n",
    "\n",
    "To learn the model you need to use the $fit(...)$ instruction and to predict you need to use the $predict(...)$ function. See the Scikit-learn documentation for how to use it (have a look at the logreg.score method too).\n",
    "\n",
    "**TO DO** Define the logistic regression model, then learn the model using the training set and predict on the test set. Then print the fraction of samples missclassified in the training set and in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "405553f98bc79df4733a62d79e4d5dd3",
     "grade": false,
     "grade_id": "cell-1319502bf0c222b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: 0.0\n",
      "Error rate on test set: 0.030612244897959183\n",
      "Compare the estimate of generalization with the sklearn implementation 0.030612244897959218\n"
     ]
    }
   ],
   "source": [
    "# TODO 7\n",
    "# Logistic regression for 2 classes\n",
    "# To compute the error rate (classification loss you can use the function \"classification_loss\" you built before)\n",
    "max_iter = None\n",
    "# YOUR CODE HERE\n",
    "model_train = linear_model.LogisticRegression(C=1e5, max_iter = 10000).fit(x_train, np.ravel(y_train))\n",
    "y_hat_train = model_train.predict(x_train)\n",
    "y_hat_test = model_train.predict(x_test)\n",
    "error_rate_training = classification_loss(y_train, y_hat_train)\n",
    "error_rate_test = classification_loss(y_test, y_hat_test)\n",
    "error_rate_test_sklearn = 1 - model_train.score(x_test, y_test)\n",
    "#raise NotImplementedError() # Remove this line\n",
    "\n",
    "print(\"Error rate on training set: \"+str(error_rate_training))\n",
    "print(\"Error rate on test set: \"+str(error_rate_test))\n",
    "print(f\"Compare the estimate of generalization with the sklearn implementation {error_rate_test_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b4c7bd126df457d4e6b716058b14d67",
     "grade": true,
     "grade_id": "cell-f61fd1d382c5083b",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(error_rate_test, error_rate_test_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06fc67cd6c1561737cca0900743ac5d0",
     "grade": false,
     "grade_id": "cell-1bc78d30e45a1810",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we do logistic regression for classification with 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07fb9f417b1d482394a832eac00d959e",
     "grade": false,
     "grade_id": "cell-a50c4e9d48fc99b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(ID_number)\n",
    "np.random.seed(ID_number)\n",
    "\n",
    "X = wine.data\n",
    "Y = wine.target\n",
    "\n",
    "m_t = 80\n",
    "x_train, y_train, x_test, y_test = create_train_val_test_datasets_with_constraints(X, Y, m_t, len(Y)-m_t, 20)\n",
    "\n",
    "_, counts = np.unique(y_train, return_counts=True)\n",
    "assert (counts >= 20).all()\n",
    "_, counts = np.unique(y_test, return_counts=True)\n",
    "assert (counts >= 20).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b0f6f414653d1853499f3532048fce",
     "grade": false,
     "grade_id": "cell-a5bafa4e2faa3712",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate on training set: 0.0\n",
      "Error rate on test set: 0.08163265306122448\n",
      "Compare the estimate of generalization with the sklearn implementation 0.08163265306122447\n"
     ]
    }
   ],
   "source": [
    "# TODO 8\n",
    "# Logistic regression for 3 classes\n",
    "# To compute the error rate (classification loss you can use the function \"classification_loss\" you built before)\n",
    "# Choose the proper number of iterations: max_iter.\n",
    "max_iter = None\n",
    "# YOUR CODE HERE\n",
    "model_train = linear_model.LogisticRegression(C=1e5, max_iter = 10000).fit(x_train, np.ravel(y_train))\n",
    "y_hat_train = model_train.predict(x_train)\n",
    "y_hat_test = model_train.predict(x_test)\n",
    "error_rate_training = classification_loss(y_train, y_hat_train)\n",
    "error_rate_test = classification_loss(y_test, y_hat_test)\n",
    "error_rate_test_sklearn = 1 - model_train.score(x_test, y_test)\n",
    "#raise NotImplementedError() # Remove this line    \n",
    "print(\"Error rate on training set: \"+str(error_rate_training))\n",
    "print(\"Error rate on test set: \"+str(error_rate_test))\n",
    "print(f\"Compare the estimate of generalization with the sklearn implementation {error_rate_test_sklearn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c389e0a9443246776714b7d8bfadea3",
     "grade": true,
     "grade_id": "cell-32dd959d8191b244",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isclose(error_rate_test, error_rate_test_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a795b02a913fa191847e2397e77ab87",
     "grade": false,
     "grade_id": "cell-a43468bc0e155db7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 9**: Answer in the next cell (you do not need more than 5-7 lines):\n",
    "\n",
    "1- Consider logistic regression on 2 and 3 classes what relation do you observe between the training error and the (estimated) true loss in both cases? Is this what you expected? Explain what you observe and why it does or does not conform to your expectations.\n",
    "\n",
    "2- Consider logistic regression on 2 and perceptron with 10000 iterations, which one would you pick? Do you expect perceptron needs more iterations? Explain what you observe and why it does or does not conform to your expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afe09c3e3ade70025d68baa76a1c23b7",
     "grade": true,
     "grade_id": "cell-5c8a6b5a5434d45a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1) It is possible to observe that the training error is equal to zero while estimated loss based on the test set not.\n",
    "#pointing the fact that in both cases the training error was less than the test error\n",
    "#It is what I expected, in fact the the training error is compute over the set used to determine the model, therefore \n",
    "#I will expect a number of missclassified points very closed to zero. On the other hand while the estimated true loss \n",
    "#is computed using the model determined through the training set and applying it to a different set, the test set, \n",
    "#so I expect to compute a bigger number of errors.\n",
    "#(2) I will pick the logistic regression algorithm because its estimate true loss is smaller. I expect that the perceptron \n",
    "#algorithm needs a huge number of iteration to compute a better estimation: it is possible to observe that increasing \n",
    "#the number of iteration from 100 to 10000 the estimate true loss decreases, so I expect that as the number of \n",
    "#iterations increases, the estimated true loss will continue to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42c19c257ab817691414cedd4daa344f",
     "grade": false,
     "grade_id": "cell-8100034bd6b75005",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We now are going to plot prediction boundaries of a logistic regression model, in order to plot them we need to reduce the number of features to 2: pick two features and restrict the dataset to include only two features, whose indices are specified in the $feature$ vector below. Then split into training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ad8af7a9eac6cd454626b87364b2daf",
     "grade": false,
     "grade_id": "cell-61db43ed3e1ffada",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO 10\n",
    "#to make the plot we need to reduce the data to 2D, so we choose two features\n",
    "features_list = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids',\n",
    "                 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "                 'Proline']\n",
    "labels_list = ['class_0', 'class_1', 'class_2']\n",
    "\n",
    "index_feature1 = 0  # You can choose the feature you prefer here\n",
    "index_feature2 = 1  # You can choose the feature you prefer here\n",
    "features = [index_feature1, index_feature2]\n",
    "\n",
    "feature_name0 = features_list[features[0]]\n",
    "feature_name1 = features_list[features[1]]\n",
    "\n",
    "X = X[:,features]\n",
    "\n",
    "# In the following we will keep the dataset with 3 classes\n",
    "m_t = 80\n",
    "x_train, y_train, x_test, y_test = create_train_val_test_datasets_with_constraints(X, Y, m_t, len(Y)-m_t, 20)\n",
    "# Fit a model on the reduced set of fetures\n",
    "# YOUR CODE HERE\n",
    "logreg = linear_model.LogisticRegression(C=1e5, max_iter = 10000).fit(x_train, np.ravel(y_train))\n",
    "#raise NotImplementedError() # Remove this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9afbdb7ca58f2157c4f16eb060f8ae0",
     "grade": true,
     "grade_id": "cell-6e35e0afddc4eb55",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert logreg.predict(x_test).shape == (x_test.shape[0], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2c1d6dfdff662b26f5a565a5f0dbe75",
     "grade": false,
     "grade_id": "cell-e052804bd400c9d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The code below uses the model in $logreg$ to plot the decision region for the two features chosen above, with colors denoting the predicted value. It also plots the points (with correct labels) in the training set. It makes a similar plot for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3463eb3529cac488e7c63459abae8cd5",
     "grade": false,
     "grade_id": "cell-0c8b1f9de040f7cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-a62ef003d687>:15: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[0].pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
      "<ipython-input-31-a62ef003d687>:28: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n",
      "  axes[1].pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test set')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x216 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "h = .02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "axes[0].pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "axes[0].scatter(x_train[:, 0], x_train[:, 1], c=y_train, edgecolors='k', cmap=plt.cm.Paired)\n",
    "axes[0].set_xlabel(feature_name0)\n",
    "axes[0].set_ylabel(feature_name1)\n",
    "\n",
    "axes[0].set_xlim(xx.min(), xx.max())\n",
    "axes[0].set_ylim(yy.min(), yy.max())\n",
    "axes[0].set_title('Training set')\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "axes[1].pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the test points \n",
    "axes[1].scatter(x_test[:, 0], x_test[:, 1], c=y_test, edgecolors='k', cmap=plt.cm.Paired, marker='s')\n",
    "axes[1].set_xlabel(feature_name0)\n",
    "axes[1].set_ylabel(feature_name1)\n",
    "\n",
    "axes[1].set_xlim(xx.min(), xx.max())\n",
    "axes[1].set_ylim(yy.min(), yy.max())\n",
    "axes[1].set_title('Test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad81e8de239addf86bc34554a54db7c2",
     "grade": false,
     "grade_id": "cell-acdf2d40b719572c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**TO DO 11**: Answer in the next cell (you do not need more than 5-7 lines):\n",
    "\n",
    "1- What is the shape of the decision boundaries? Why?\n",
    "\n",
    "2- In this lower dimensional space, are the features linearily separable? What if you consider the entire feature vector (without any dimensionality reduction)?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73a023e7e2714dd35c92f77ec982d640",
     "grade": true,
     "grade_id": "cell-5a2bb524ef017bac",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(1)The shape of the decision boundaries are straight lines, becouse to be determined an linear classification algorithm\n",
    "#has been used.\n",
    "#(2)By the graphs, it is possible to see that the features are non linearly separable. If we consider the entire\n",
    "#feature vector there could be a hyperplane capable of linearly separating all points."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1f40f8c330d568234d1a24f8987a48272071e5b522e677ff6ccdd68d8171358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
